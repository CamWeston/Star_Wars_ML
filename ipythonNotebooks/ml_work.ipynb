{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_iv = pd.read_csv('SW_EpisodeIV.txt', delim_whitespace=True, header=0, escapechar='\\\\')\n",
    "ep_v = pd.read_csv('SW_EpisodeV.txt', delim_whitespace=True, header=0, escapechar='\\\\')\n",
    "ep_vi = pd.read_csv('SW_EpisodeVI.txt', delim_whitespace=True, header=0, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eps = (ep_iv.append(ep_v, ignore_index=True)).append(ep_vi, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe with dialogue from just characters that have more than 48 lines\n",
    "sw_highs = all_eps[all_eps.groupby('character').character.transform(len) >= 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LUKE        494\n",
       "HAN         459\n",
       "THREEPIO    301\n",
       "LEIA        227\n",
       "VADER       140\n",
       "BEN         115\n",
       "LANDO       101\n",
       "YODA         49\n",
       "Name: character, dtype: int64"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_highs['character'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1886, 2)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw_highs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_highs = sw_highs.sample(frac=1).reset_index(drop=True)\n",
    "sw_train = sw_highs.loc[:1600]\n",
    "sw_test = sw_highs.loc[1601:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()),])\n",
    "text_clf = text_clf.fit(sw_train.dialogue, sw_train.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37894736842105264"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = text_clf.predict(sw_test.dialogue)\n",
    "np.mean(predicted == sw_test.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3824561403508772"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_no_stop_words = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()), ])\n",
    "predicted_no_stop_words = text_clf_no_stop_words.fit(sw_train.dialogue, sw_train.character)\n",
    "predicted_no_stop_words = text_clf_no_stop_words.predict(sw_test.dialogue)\n",
    "np.mean(predicted_no_stop_words == sw_test.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate each line of dialogue to one character\n",
    "sw_grouped_quotes_train = sw_train.groupby(['character'])['dialogue'].apply(lambda text: ''.join(text.to_string(index=False))).str.replace('(\\\\n)', '').reset_index()\n",
    "sw_grouped_quotes_test = sw_test.groupby(['character'])['dialogue'].apply(lambda text: ''.join(text.to_string(index=False))).str.replace('(\\\\n)', '').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nsw = no stop words; using Multinomial NB \n",
    "sw_grouped_nsw_pipeline = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()), ])\n",
    "sw_grouped_nsw = sw_grouped_nsw_pipeline.fit(sw_grouped_quotes_train.dialogue, sw_grouped_quotes_train.character)\n",
    "sw_grouped_nsw = sw_grouped_nsw_pipeline.predict(sw_grouped_quotes_test.dialogue)\n",
    "np.mean(sw_grouped_nsw == sw_grouped_quotes_test.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BEN' 'HAN' 'HAN' 'HAN' 'LUKE' 'THREEPIO' 'VADER' 'BEN']\n"
     ]
    }
   ],
   "source": [
    "print(sw_grouped_nsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "# Using SGD Classifier grouped character dialogue (shifted before compilation), currently best algorithm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sw_grouped_nsw_pipeline_sgd = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)),])\n",
    "sw_grouped_nsw_sgd = sw_grouped_nsw_pipeline_sgd.fit(sw_grouped_quotes_train.dialogue, sw_grouped_quotes_train.character)\n",
    "sw_grouped_nsw_sgd = sw_grouped_nsw_pipeline_sgd.predict(sw_grouped_quotes_test.dialogue)\n",
    "print('SGD Classifier Accuracy:', np.mean(sw_grouped_nsw_sgd == sw_grouped_quotes_test.character))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction   True Value\n",
      "YODA         BEN\n",
      "HAN          HAN\n",
      "HAN          LANDO\n",
      "HAN          LEIA\n",
      "LUKE         LUKE\n",
      "THREEPIO     THREEPIO\n",
      "VADER        VADER\n",
      "YODA         YODA\n",
      "SGD Classifier Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "predictions = sw_grouped_nsw_sgd\n",
    "actual_values = sw_grouped_quotes_test.character.tolist()\n",
    "print(\"{0:12s} {1}\".format(\"Prediction\", \"True Value\"))\n",
    "for x, y in zip(predictions, actual_values): \n",
    "    print(\"{0:12s} {1}\".format(x, y))\n",
    "print('SGD Classifier Accuracy:', np.mean(sw_grouped_nsw_sgd == sw_grouped_quotes_test.character))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Actual values\n",
    "sw_grouped_quotes_test\n",
    "\n",
    "sw_grouped_nsw_pipeline_sgd = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)),])\n",
    "sw_grouped_nsw_sgd = sw_grouped_nsw_pipeline_sgd.fit(sw_grouped_quotes_train.dialogue, sw_grouped_quotes_train.character)\n",
    "sw_grouped_nsw_sgd = sw_grouped_nsw_pipeline_sgd.predict(sw_grouped_quotes_test.dialogue)\n",
    "print('SGD Classifier Accuracy:', np.mean(sw_grouped_nsw_sgd == sw_grouped_quotes_test.character))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "accuracy = 0\n",
    "sw = all_eps[all_eps.groupby('character').character.transform(len) >= 49]\n",
    "# while accuracy <= 0.9:\n",
    "    \n",
    "# Construct data\n",
    "new_df = sw.sample(frac=1).reset_index(drop=True)\n",
    "train_df = new_df.loc[:1600]\n",
    "test_df = new_df.loc[1601:]\n",
    "train_df_grouped = train_df.groupby(['character'])['dialogue'].apply(lambda text: ''.join(text.to_string(index=False))).str.replace('(\\\\n)', '').reset_index()\n",
    "test_df_grouped = test_df.groupby(['character'])['dialogue'].apply(lambda text: ''.join(text.to_string(index=False))).str.replace('(\\\\n)', '').reset_index()\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)),])\n",
    "sgd = pipeline.fit(train_df_grouped.dialogue, train_df_grouped.character)\n",
    "sgd = pipeline.predict(test_df_grouped.dialogue)\n",
    "accuracy = np.mean(sw_grouped_nsw_sgd == sw_grouped_quotes_test.character)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
